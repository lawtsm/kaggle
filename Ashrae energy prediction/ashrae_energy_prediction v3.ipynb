{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notes\n",
    "#meter - The meter id code. \n",
    "#Read as {0: electricity, 1: chilledwater, 2: steam, 3: hotwater}. Not every building has all meter types.\n",
    "\n",
    "#Sites: 0, 1, 2, ..., 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import time, datetime, warnings, os, random, gc, pickle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.base import clone\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def compress_df(bigdf, exception=[]):\n",
    "    initial_mem = bigdf.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage of {}: {} MB\".format(get_df_name(bigdf), initial_mem))\n",
    "    \n",
    "    cols = list(bigdf.columns)\n",
    "    for x in exception:\n",
    "        cols.remove(x)\n",
    "    \n",
    "    for col in cols:\n",
    "        col_data = bigdf[col]\n",
    "        col_type = col_data.dtype.name\n",
    "        if col_type == 'object':\n",
    "            bigdf[col] = pd.to_numeric(col_data.astype('category').cat.codes, downcast=\"integer\")\n",
    "        elif col_type == 'bool':\n",
    "            bigdf[col] = col_data.astype('int8')\n",
    "        elif col_type.startswith('int') or (col_data.round() == col_data).all():\n",
    "            bigdf[col] = pd.to_numeric(col_data, downcast='integer')\n",
    "        else:\n",
    "            bigdf[col] = pd.to_numeric(col_data, downcast='float')\n",
    "    \n",
    "    final_mem = bigdf.memory_usage().sum() / 1024**2\n",
    "    print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(final_mem, 100 * (initial_mem - final_mem) / initial_mem))\n",
    "    \n",
    "    return bigdf\n",
    "\n",
    "def adjust_weather(df):\n",
    "    \n",
    "    site_offsets = [-5, 0, -7, -5, -8, 0, -5, -5, -5, -6, -7, -5, 0, -6, -5, -5]\n",
    "    offset_map = {site: offset for site, offset in enumerate(site_offsets)}\n",
    "    df.timestamp = df.apply(lambda x: x['timestamp'] + datetime.timedelta(hours=offset_map[x['site_id']]), axis=1)\n",
    "    \n",
    "    site_dfs = []\n",
    "    \n",
    "    if get_df_name(df) == 'train_weather_df':\n",
    "        n = range(8784)\n",
    "    else:\n",
    "        n = range(8784, 26304)\n",
    "        \n",
    "    df['timestamp2'] = (df.timestamp - pd.to_datetime(\"2016-01-01\")).dt.total_seconds() // 3600\n",
    "\n",
    "    for site_id in df.site_id.unique():\n",
    "        site_df = df[df.site_id == site_id].set_index('timestamp2').reindex(n)\n",
    "        site_df.site_id = site_id\n",
    "        for col in [c for c in site_df.columns if c not in ['timestamp', 'site_id']]:\n",
    "            site_df[f\"had_{col}\"] = ~site_df[col].isna()\n",
    "            site_df[col] = site_df[col].interpolate(limit_direction='both', method='linear')\n",
    "            site_df[col] = site_df[col].fillna(df[col].median())\n",
    "        site_dfs.append(site_df)\n",
    "    df = pd.concat(site_dfs).reset_index()\n",
    "    \n",
    "    df.drop('timestamp2', axis=1, inplace=True)\n",
    "    \n",
    "    for col in [c for c in df.columns if c != 'timestamp']:\n",
    "        if df[col].isna().any(): df[f'had_{col}'] = ~df[col].isna().astype('bool')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading train data')\n",
    "train_df = pd.read_csv('../input/ashrae-energy-prediction/train.csv', parse_dates=['timestamp'])\n",
    "building_df = pd.read_csv('../input/ashrae-energy-prediction/building_metadata.csv').fillna(-1)\n",
    "building_df = compress_df(building_df)\n",
    "train_weather_df = pd.read_csv('../input/ashrae-energy-prediction/weather_train.csv', parse_dates=['timestamp'])\n",
    "\n",
    "print ('Fix train weather data')\n",
    "train_weather_df = adjust_weather(train_weather_df)\n",
    "train_weather_df = compress_df(train_weather_df, ['timestamp']).set_index(['site_id', 'timestamp'])\n",
    "\n",
    "print('Merging train data')\n",
    "train_df = pd.merge(train_df, building_df, on='building_id', how='left')\n",
    "train_df = train_df.set_index(['site_id', 'timestamp']).join(train_weather_df, on = ['site_id', 'timestamp']).fillna(-1)\n",
    "train_df = compress_df(train_df).reset_index()\n",
    "\n",
    "del train_weather_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading test data')\n",
    "test_df = pd.read_csv('../input/ashrae-energy-prediction/test.csv', parse_dates=['timestamp'])\n",
    "test_weather_df = pd.read_csv('../input/ashrae-energy-prediction/weather_test.csv', parse_dates=['timestamp'])\n",
    "\n",
    "print ('Fix test weather data')\n",
    "test_weather_df = adjust_weather(test_weather_df)\n",
    "test_weather_df = compress_df(test_weather_df, ['timestamp']).set_index(['site_id', 'timestamp'])\n",
    "\n",
    "print('Merging test data')\n",
    "test_df = pd.merge(test_df, building_df, on='building_id', how='left')\n",
    "test_df = test_df.set_index(['site_id', 'timestamp']).join(test_weather_df, on = ['site_id', 'timestamp']).fillna(-1)\n",
    "test_df = compress_df(test_df).reset_index()\n",
    "\n",
    "del test_weather_df, building_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of Data')\n",
    "print('Train:{}'.format(train_df.shape))\n",
    "print('Test:{}'.format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_is_bad_zero(Xy_subset, min_interval=48, summer_start=3000, summer_end=7500):\n",
    "    meter = Xy_subset.meter_id.iloc[0]\n",
    "    is_zero = Xy_subset.meter_reading == 0\n",
    "    if meter == 0:\n",
    "        # Electrical meters should never be zero. Keep all zero-readings in this table so that\n",
    "        # they will all be dropped in the train set.\n",
    "        return is_zero\n",
    "\n",
    "    transitions = (is_zero != is_zero.shift(1))\n",
    "    all_sequence_ids = transitions.cumsum()\n",
    "    ids = all_sequence_ids[is_zero].rename(\"ids\")\n",
    "    if meter in [2, 3]:\n",
    "        # It's normal for steam and hotwater to be turned off during the summer\n",
    "        keep = set(ids[(Xy_subset.timestamp < summer_start) |\n",
    "                       (Xy_subset.timestamp > summer_end)].unique())\n",
    "        is_bad = ids.isin(keep) & (ids.map(ids.value_counts()) >= min_interval)\n",
    "    elif meter == 1:\n",
    "        time_ids = ids.to_frame().join(Xy_subset.timestamp).set_index(\"timestamp\").ids\n",
    "        is_bad = ids.map(ids.value_counts()) >= min_interval\n",
    "\n",
    "        # Cold water may be turned off during the winter\n",
    "        jan_id = time_ids.get(0, False)\n",
    "        dec_id = time_ids.get(8283, False)\n",
    "        if (jan_id and dec_id and jan_id == time_ids.get(500, False) and\n",
    "                dec_id == time_ids.get(8783, False)):\n",
    "            is_bad = is_bad & (~(ids.isin(set([jan_id, dec_id]))))\n",
    "    else:\n",
    "        raise Exception(f\"Unexpected meter type: {meter}\")\n",
    "\n",
    "    result = is_zero.copy()\n",
    "    result.update(is_bad)\n",
    "    return result\n",
    "\n",
    "def find_bad_zeros(X):\n",
    "    \"\"\"Returns an Index object of the rows which should be deleted.\"\"\"\n",
    "    Xy = X.assign(meter_reading=X.meter_reading, meter_id=X.meter)\n",
    "    is_bad_zero = Xy.groupby([\"building_id\", \"meter\"]).apply(make_is_bad_zero)\n",
    "    return is_bad_zero[is_bad_zero].index.droplevel([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Outlier detection & Meter comparisons')\n",
    "for i in range(0, 16):\n",
    "    train_df2 = train_df[train_df['site_id']==i]\n",
    "    temp_df = train_df2.groupby(['meter', 'timestamp']).meter_reading.mean().reset_index()\n",
    "    ax = sns.FacetGrid(temp_df, col='meter', col_wrap=2, height=4, aspect=2,  sharey=False)\n",
    "    ax.map(plt.plot, 'timestamp', 'meter_reading', color=\"teal\", linewidth = 3).set_titles('Site ' + str(i) + ' Meter {col_name}')\n",
    "    plt.subplots_adjust(hspace=0.45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepdata(df):\n",
    "    #Categorical\n",
    "    le = LabelEncoder()\n",
    "    df.primary_use = le.fit_transform(df.primary_use)\n",
    "    \n",
    "    gc.collect()\n",
    "\n",
    "    #Convert to datetime\n",
    "    df['hour'] = df.timestamp.dt.hour.astype(np.int8)\n",
    "    df['weekday'] = df.timestamp.dt.weekday.astype(np.int8)\n",
    "    #df['day_year'] = df.timestamp.dt.dayofyear.astype(np.int16)\n",
    "    #df['month'] = df.timestamp.dt.month.astype(np.int16)\n",
    "    #df['dayofmonth'] = df.timestamp.dt.day.astype(np.int8)\n",
    "    \n",
    "    #Rescaling\n",
    "    minyear = df.year_built.min()\n",
    "    df.year_built = df.year_built - minyear\n",
    "    df.square_feet = np.log1p(df.square_feet)\n",
    "    \n",
    "    #Train_df\n",
    "    if get_df_name(df) == 'train_df':\n",
    "        df.reset_index(drop=True)\n",
    "        df.sort_values('timestamp')\n",
    "    \n",
    "    #Removing features\n",
    "    #features = ['sea_level_pressure', 'wind_direction', 'wind_speed']\n",
    "    #df.drop(features, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "train_df = prepdata(train_df)\n",
    "\n",
    "test_df = prepdata(test_df)\n",
    "row_ids = test_df.row_id\n",
    "test_df.drop('row_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing bad records\n",
    "print('Removing initial observations for site_id=0')\n",
    "train_df = train_df[~((train_df['site_id'] == 0) & (train_df['meter'] == 0) & (train_df['timestamp'] < datetime.date(2016, 5, 1)))]\n",
    "\n",
    "print('Removing uneasonably large observations for meter 2 of building 1099')\n",
    "train_df = train_df[~((train_df['building_id'] == 1099) & (train_df['meter'] == 2) & (train_df['meter_reading'] > 3e4))]\n",
    "\n",
    "print('Removing bad zeroes')\n",
    "train_df['timestamp'] = (train_df.timestamp - pd.to_datetime(\"2016-01-01\")).dt.total_seconds() // 3600\n",
    "badrows = find_bad_zeros(train_df[['timestamp', 'building_id', 'meter', 'meter_reading']])\n",
    "train_df.drop(index=list(badrows), inplace=True)\n",
    "del badrows\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.log1p(train_df.meter_reading)\n",
    "train_df.drop(['meter_reading', 'timestamp'], axis=1, inplace=True)\n",
    "test_df.drop('timestamp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Fitting LGBM regressor for meters 0, 1, 2 and 3')\n",
    "fitted = {}\n",
    "importances = []\n",
    "cat = ['building_id', 'site_id', 'primary_use', 'hour', 'weekday', 'had_air_temperature', 'had_cloud_coverage', \n",
    "       'had_dew_temperature', 'had_precip_depth_1_hr', 'had_sea_level_pressure', 'had_wind_direction', 'had_wind_speed'] #'meter',\n",
    "model = LGBMRegressor(boosting_type='gbdt', num_leaves=100, max_depth=-1, learning_rate=0.05, n_estimators=100,\n",
    "                      colsample_bytree=0.85, reg_lambda=2, metric='rmse', random_state=0)\n",
    "result = np.zeros(len(test_df))\n",
    "\n",
    "for val in train_df.meter.unique():\n",
    "    X1 = train_df[train_df.meter == val].drop('meter', axis=1)\n",
    "    fitted[val] = clone(model).fit(X1, train_y.loc[X1.index], categorical_feature=cat)\n",
    "    importances.append(fitted[val].feature_importances_)\n",
    "    del X1\n",
    "    ix = np.nonzero((test_df['meter'] == val).to_numpy())\n",
    "    result[ix] = fitted[val].predict(test_df.iloc[ix].drop('meter', axis=1))\n",
    "    \n",
    "del train_df, train_y\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model predictions')\n",
    "predict = np.expm1(result)\n",
    "\n",
    "del test_df\n",
    "\n",
    "print('Averaging')\n",
    "pred = np.clip(predict, 0, None)\n",
    "#pred = np.clip(np.round_(predict, decimals = 2), 0, None)\n",
    "\n",
    "submission = pd.DataFrame({'row_id': row_ids, 'meter_reading': pred})\n",
    "submission.to_csv('submission.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    lgb.plot_importance(fitted[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
